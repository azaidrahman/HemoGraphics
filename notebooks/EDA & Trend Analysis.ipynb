{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from helper_functions import load_csvs_from_data_folder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "    \n",
    "#Todays date\n",
    "today_str = datetime.now().strftime('%Y-%m-%d')\n",
    "data_folder = '..\\\\data'\n",
    "\n",
    "# Load dataframes from CSVs\n",
    "dfs = load_csvs_from_data_folder(data_folder, today_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA for donations_facility:\n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145266 entries, 0 to 145265\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   date                     145266 non-null  datetime64[ns]\n",
      " 1   hospital                 145266 non-null  object        \n",
      " 2   daily                    145266 non-null  int64         \n",
      " 3   blood_a                  145266 non-null  int64         \n",
      " 4   blood_b                  145266 non-null  int64         \n",
      " 5   blood_o                  145266 non-null  int64         \n",
      " 6   blood_ab                 145266 non-null  int64         \n",
      " 7   location_centre          145266 non-null  int64         \n",
      " 8   location_mobile          145266 non-null  int64         \n",
      " 9   type_wholeblood          145266 non-null  int64         \n",
      " 10  type_apheresis_platelet  145266 non-null  int64         \n",
      " 11  type_apheresis_plasma    145266 non-null  int64         \n",
      " 12  type_other               145266 non-null  int64         \n",
      " 13  social_civilian          145266 non-null  int64         \n",
      " 14  social_student           145266 non-null  int64         \n",
      " 15  social_policearmy        145266 non-null  int64         \n",
      " 16  donations_new            145266 non-null  int64         \n",
      " 17  donations_regular        145266 non-null  int64         \n",
      " 18  donations_irregular      145266 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(17), object(1)\n",
      "memory usage: 21.1+ MB\n",
      "\n",
      "==================================================\n",
      "\n",
      "EDA for donations_state:\n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92442 entries, 0 to 92441\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   date                     92442 non-null  datetime64[ns]\n",
      " 1   state                    92442 non-null  object        \n",
      " 2   daily                    92442 non-null  int64         \n",
      " 3   blood_a                  92442 non-null  int64         \n",
      " 4   blood_b                  92442 non-null  int64         \n",
      " 5   blood_o                  92442 non-null  int64         \n",
      " 6   blood_ab                 92442 non-null  int64         \n",
      " 7   location_centre          92442 non-null  int64         \n",
      " 8   location_mobile          92442 non-null  int64         \n",
      " 9   type_wholeblood          92442 non-null  int64         \n",
      " 10  type_apheresis_platelet  92442 non-null  int64         \n",
      " 11  type_apheresis_plasma    92442 non-null  int64         \n",
      " 12  type_other               92442 non-null  int64         \n",
      " 13  social_civilian          92442 non-null  int64         \n",
      " 14  social_student           92442 non-null  int64         \n",
      " 15  social_policearmy        92442 non-null  int64         \n",
      " 16  donations_new            92442 non-null  int64         \n",
      " 17  donations_regular        92442 non-null  int64         \n",
      " 18  donations_irregular      92442 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(17), object(1)\n",
      "memory usage: 13.4+ MB\n",
      "\n",
      "==================================================\n",
      "\n",
      "EDA for newdonors_facility:\n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145266 entries, 0 to 145265\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count   Dtype         \n",
      "---  ------    --------------   -----         \n",
      " 0   date      145266 non-null  datetime64[ns]\n",
      " 1   hospital  145266 non-null  object        \n",
      " 2   17-24     145266 non-null  int64         \n",
      " 3   25-29     145266 non-null  int64         \n",
      " 4   30-34     145266 non-null  int64         \n",
      " 5   35-39     145266 non-null  int64         \n",
      " 6   40-44     145266 non-null  int64         \n",
      " 7   45-49     145266 non-null  int64         \n",
      " 8   50-54     145266 non-null  int64         \n",
      " 9   55-59     145266 non-null  int64         \n",
      " 10  60-64     145266 non-null  int64         \n",
      " 11  other     145266 non-null  int64         \n",
      " 12  total     145266 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(11), object(1)\n",
      "memory usage: 14.4+ MB\n",
      "\n",
      "==================================================\n",
      "\n",
      "EDA for newdonors_state:\n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92442 entries, 0 to 92441\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    92442 non-null  datetime64[ns]\n",
      " 1   state   92442 non-null  object        \n",
      " 2   17-24   92442 non-null  int64         \n",
      " 3   25-29   92442 non-null  int64         \n",
      " 4   30-34   92442 non-null  int64         \n",
      " 5   35-39   92442 non-null  int64         \n",
      " 6   40-44   92442 non-null  int64         \n",
      " 7   45-49   92442 non-null  int64         \n",
      " 8   50-54   92442 non-null  int64         \n",
      " 9   55-59   92442 non-null  int64         \n",
      " 10  60-64   92442 non-null  int64         \n",
      " 11  other   92442 non-null  int64         \n",
      " 12  total   92442 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(11), object(1)\n",
      "memory usage: 9.2+ MB\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def perform_eda(df, name):\n",
    "    print(f\"EDA for {name}:\")\n",
    "    \n",
    "    # print(\"\\nFirst few rows:\")\n",
    "    # print(df.iloc[:,:5].head())\n",
    "    \n",
    "    print(\"\\nInfo:\")\n",
    "    df.info()\n",
    "    \n",
    "    # Display basic statistics\n",
    "    # print(\"\\nDescribe:\")\n",
    "    # print(df.describe())\n",
    "    \n",
    "    # Check for null values\n",
    "    # print(\"\\nNull values:\")\n",
    "    # print(df.isnull().sum())\n",
    "    \n",
    "    # Check for duplicate rows\n",
    "    # print(\"\\nNumber of duplicate rows:\")\n",
    "    # print(df.duplicated().sum())\n",
    "\n",
    "# Perform EDA on each dataframe\n",
    "for name, df in dfs.items():\n",
    "    perform_eda(df, name)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "Malaysia             6603\n",
       "Johor                6603\n",
       "Kedah                6603\n",
       "Kelantan             6603\n",
       "Melaka               6603\n",
       "Negeri Sembilan      6603\n",
       "Pahang               6603\n",
       "Perak                6603\n",
       "Pulau Pinang         6603\n",
       "Sabah                6603\n",
       "Sarawak              6603\n",
       "Selangor             6603\n",
       "Terengganu           6603\n",
       "W.P. Kuala Lumpur    6603\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observing the values in the state columns\n",
    "dfs['donations_state']['state'].value_counts()\n",
    "\n",
    "#Malaysia is not a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26448\\151597437.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#Lets answer the question on why is there a malaysia state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdonations_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'donations_state'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#Set the dates into datetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdonations_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdonations_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdonations_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mdonations_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#Separate Malaysia and other states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Projects\\Data Science\\GovTech\\hemogoblins\\venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4077\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4078\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4079\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4080\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4081\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4082\u001b[0m         elif (\n\u001b[0;32m   4083\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4084\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Projects\\Data Science\\GovTech\\hemogoblins\\venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4205\u001b[0m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4206\u001b[0m             \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4207\u001b[0m             \u001b[0mlen_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4208\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen_cols\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4209\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Columns must be same length as key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4211\u001b[0m             \u001b[1;31m# align right-hand-side columns if self.columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4212\u001b[0m             \u001b[1;31m# is multi-index and self[key] is a sub-frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "# Define the main outputs and the corresponding columns in dataframes\n",
    "variable_outputs = {\n",
    "    'blood_type': ['blood_a', 'blood_b', 'blood_o', 'blood_ab'],\n",
    "    'location': ['location_centre', 'location_mobile'],\n",
    "    'donation_type': ['type_wholeblood', 'type_apheresis_platelet', 'type_apheresis_plasma', 'type_other'],\n",
    "    'social_class': ['social_civilian', 'social_student', 'social_policearmy'],\n",
    "    'donation_regularity': ['donations_new', 'donations_regular', 'donations_irregular'],\n",
    "}\n",
    "\n",
    "#Lets answer the question on why is there a malaysia state\n",
    "donations_state = dfs['donations_state']\n",
    "print(donations_state)\n",
    "#Set the dates into datetime\n",
    "# donations_state['date'] = donations_state.assign(date=pd.to_datetime(donations_state[\"date\"])).set_index(\"date\")\n",
    "# donations_state.set_index('date',inplace=True)\n",
    "\n",
    "#Separate Malaysia and other states\n",
    "malaysia_total = donations_state[donations_state['state'] == 'Malaysia']['daily'].sum()\n",
    "state_total = donations_state[donations_state['state'] != 'Malaysia']['daily'].sum()\n",
    "# print(malaysia_total, state_total)\n",
    "donations_state['state'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay evidently its just an aggregate of all the states on any given date. Therefore lets separate it as a different df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into two DataFrames: one for Malaysia and one for the states\n",
    "ms_df = donations_state.loc[donations_state['state'] == 'Malaysia', :]\n",
    "state_df = donations_state.loc[donations_state['state'] != 'Malaysia', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first few rows to ensure the DataFrame looks as expected\n",
    "print(state_df.loc[ :,['state','daily'] ].head())\n",
    "print(ms_df.loc[:,'daily'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets analyse the states first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by state and resample to a monthly frequency, summing the daily donations\n",
    "monthly_donations_by_state = state_df.groupby('state').resample('M').sum().loc[:, 'daily']\n",
    "\n",
    "# Plotting the trends\n",
    "plt.figure(figsize=(25, 15))\n",
    "for state in monthly_donations_by_state.index.get_level_values(0).unique():\n",
    "    monthly_donations_by_state.xs(state, level='state').plot(label=state)\n",
    "plt.title('Monthly Blood Donations by State')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Donations')\n",
    "plt.legend(title='State')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First impressions**\n",
    "\n",
    "- KL is by far the leader in volume of blood donations, hovering around 12,500-15,000 blood donations monthly.\n",
    "- All the other states all are only below 5,000 monthly donations a month.\n",
    "\n",
    "\n",
    "**A few things to note**\n",
    "\n",
    "- Negeri Sembilan only started donating blood in 2014. \n",
    "- Kelantan stopped donating in 2017-2018.\n",
    "- Sharp decline in Kedah after 2019 (Presumably from Covid)(Kedah does include Penang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets look into the other states now\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose as sm\n",
    "\n",
    "monthly_donations_by_state = state_df.groupby(['state', pd.Grouper(freq='M')])['daily'].sum()\n",
    "\n",
    "# Pivot the table to have states as columns and dates as rows\n",
    "monthly_donations_by_state = monthly_donations_by_state.unstack(level=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_and_plot(state, df, mean_donations = None, model='additive'):\n",
    "    # Check if the state's data exists in the DataFrame\n",
    "    if state not in df.columns:\n",
    "        print(f\"No data for state: {state}\")\n",
    "        return\n",
    "    \n",
    "    if mean_donations is not None:\n",
    "        rank = mean_donations.rank(ascending=False)[state]\n",
    "    \n",
    "    # Perform seasonal decomposition\n",
    "    series = df[state].dropna()  # Drop NA values for decomposition\n",
    "    decomposition = sm(series, model=model, period=12)  # Monthly data usually has a period of 12\n",
    "    \n",
    "    # Plot the decomposed components\n",
    "    fig, axes = plt.subplots(4, 1, sharex=True, figsize=(12, 8))\n",
    "    decomposition.observed.plot(ax=axes[0], legend=False, title='Observed')\n",
    "    decomposition.trend.plot(ax=axes[1], legend=False, title='Trend')\n",
    "    decomposition.seasonal.plot(ax=axes[2], legend=False, title='Seasonal')\n",
    "    decomposition.resid.plot(ax=axes[3], legend=False, title='Residual')\n",
    "   \n",
    "    if mean_donations is not None : \n",
    "        plt.suptitle(f'Seasonal Decompose of {state} Blood Donations (Rank {int(rank)})')\n",
    "    else:\n",
    "        plt.suptitle(f'Seasonal Decompose of {state} Blood Donations')\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust the layout\n",
    "    plt.show()\n",
    "\n",
    "# print(high_states)\n",
    "# print(low_states)\n",
    "# Decompose and plot for the selected states\n",
    "# for state in high_states.union(low_states):\n",
    "#     decompose_and_plot(state, monthly_donations_by_state, 'multiplicative')\n",
    "\n",
    "#Doesnt work with multiplicative!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_cleans_before_decompose(df):\n",
    "    #Forward-fill, replace NA and ensure no negative values in the dataset\n",
    "    df.ffill()\n",
    "    df.fillna(0,inplace=True)\n",
    "    df[df < 0] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean donations per state to determine highest and lowest\n",
    "mean_donations = monthly_donations_by_state.mean().sort_values()\n",
    "\n",
    "# Take two states with the highest and two with the lowest mean donations\n",
    "if mean_donations is not None:\n",
    "    high_states = mean_donations.index[-2:]\n",
    "    low_states = mean_donations.index[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_donations_by_state_ffill = df_cleans_before_decompose(monthly_donations_by_state)\n",
    "# Now, can safely proceed with an additive model\n",
    "for state in high_states.union(low_states):\n",
    "    decompose_and_plot(state, monthly_donations_by_state_ffill, mean_donations,model= 'additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal decompose of Malaysia\n",
    "monthly_donations_malaysia = ms_df.groupby(['state', pd.Grouper(freq='M')])['daily'].sum().unstack(level=0)\n",
    "\n",
    "decompose_and_plot('Malaysia',monthly_donations_malaysia,model='additive' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "adf_result_malaysia = adfuller(monthly_donations_malaysia)\n",
    "kpss_result_malaysia = kpss(monthly_donations_malaysia,regression = 'c')\n",
    "\n",
    "print(adf_result_malaysia,\"\\n###########################\\n\",kpss_result_malaysia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Statistical Tests\n",
    "\n",
    "### The Augmented Dickey-Fuller (ADF) test and the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test results provide with information about the stationarity of the blood donation time series data for Malaysia:\n",
    "\n",
    "### ADF Test Result:\n",
    "\n",
    "Test Statistic: -2.3188\n",
    "p-value: 0.1659\n",
    "Number of Lags Used: 14\n",
    "Number of Observations Used: 202\n",
    "Critical Values: {'1%': -3.4631, '5%': -2.8759, '10%': -2.5745}\n",
    "KPSS Test Result:\n",
    "\n",
    "Test Statistic: 1.8849\n",
    "p-value: 0.01\n",
    "Number of Lags Used: 9\n",
    "Critical Values: {'10%': 0.347, '5%': 0.463, '2.5%': 0.574, '1%': 0.739}\n",
    "\n",
    "## Summary: \n",
    "\n",
    "The ADF test has a p-value greater than 0.05, which suggests that we cannot reject the null hypothesis of the presence of a unit root. This means the series is not stationary and may have a time-dependent structure.\n",
    "\n",
    "The KPSS test, on the other hand, has a test statistic higher than the critical values, and a p-value of 0.01, which suggests that we can reject the null hypothesis of stationarity. This indicates that the series is non-stationary and has a trend.\n",
    "\n",
    "Given these results, the trend in the blood donation data for Malaysia is statistically significant, implying that the donations data exhibits a systematic trend over time. However, the non-stationarity of the series also suggests that any model we use to predict future values should account for this trend component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the Malaysia level data showed a non-stationary trend, let's perform the ADF and KPSS tests for each state.\n",
    "# We will compile the results in a DataFrame for easier comparison.\n",
    "\n",
    "# Initialize a DataFrame to store the test results\n",
    "trend_tests_results_list = []\n",
    "\n",
    "# Threshold\n",
    "adf_threshold = 0.05\n",
    "kpss_threshold = 0.05\n",
    "\n",
    "# Loop through each state and perform the tests\n",
    "for state in state_df['state'].unique():\n",
    "    \n",
    "    # Prepare the time series data for the current state\n",
    "    state_series = state_df[state_df['state'] == state].resample('M').sum()['daily']\n",
    "    \n",
    "    # Perform ADF test\n",
    "    adf_stat, adf_p, _, _, _, _ = adfuller(state_series.dropna(), autolag='AIC')\n",
    "    \n",
    "    # Perform KPSS test\n",
    "    kpss_stat, kpss_p, _, _ = kpss(state_series.dropna(), regression='c')\n",
    "\n",
    "    # Determine stationarity based on p-value thresholds\n",
    "    is_stationary_adf = 'Yes' if adf_p < adf_threshold else 'No'\n",
    "    is_stationary_kpss = 'Yes' if kpss_p > kpss_threshold else 'No'\n",
    "\n",
    "    # Append the results\n",
    "    result_df = pd.DataFrame({\n",
    "        'State': [state],\n",
    "        'ADF Statistic': [adf_stat],\n",
    "        'ADF p-value': [adf_p],\n",
    "        'Is Stationary (ADF)': [is_stationary_adf],\n",
    "        'KPSS Statistic': [kpss_stat],\n",
    "        'KPSS p-value': [kpss_p],\n",
    "        'Is Stationary (KPSS)': [is_stationary_kpss]\n",
    "    })\n",
    "    trend_tests_results_list.append(result_df)\n",
    "\n",
    "trend_tests_results = pd.concat(trend_tests_results_list,ignore_index=True)\n",
    "trend_tests_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To analyze the differenced series and confirm stationarity, we will first difference the data and then re-run the ADF test.\n",
    "\n",
    "# Let's create a function to perform differencing and conduct the ADF test\n",
    "def test_stationarity_of_differenced_series(series, adf_threshold=0.05):\n",
    "    # Perform differencing to remove trends\n",
    "    differenced_series = series.diff().dropna()\n",
    "    \n",
    "    # Conduct ADF test on the differenced series\n",
    "    adf_result = adfuller(differenced_series, autolag='AIC')\n",
    "    \n",
    "    # Determine if the series is stationary based on the ADF test p-value\n",
    "    is_stationary = adf_result[1] < adf_threshold\n",
    "    \n",
    "    # Return the differenced series and the ADF test result\n",
    "    return differenced_series, adf_result, is_stationary\n",
    "\n",
    "# Initialize a DataFrame to store the differencing results\n",
    "differencing_results_list = []\n",
    "\n",
    "# Loop through each state and test the stationarity of the differenced series\n",
    "for state in state_df['state'].unique():\n",
    "    \n",
    "    # Extract the time series data for the current state\n",
    "    state_series = state_df[state_df['state'] == state].resample('M').sum()['daily']\n",
    "    \n",
    "    # Test the stationarity of the differenced series\n",
    "    _, adf_result, is_stationary = test_stationarity_of_differenced_series(state_series)\n",
    "    \n",
    "    # Append the results to the DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        'State': [state],\n",
    "        'ADF Statistic': [adf_result[0]],\n",
    "        'ADF p-value': [adf_result[1]],\n",
    "        'Is Stationary': [is_stationary]\n",
    "    })\n",
    "    differencing_results_list.append(result_df)\n",
    "\n",
    "differencing_results = pd.concat(differencing_results_list,ignore_index=True)\n",
    "differencing_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
